{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices: [6 2]\n",
      "Indices: [4 8]\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n",
      "Error: Empty image passed to keypoint detection.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Load YOLO Model\n",
    "def load_yolo_model(cfg_path, weights_path, names_path):\n",
    "    net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    with open(names_path, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return net, output_layers, classes\n",
    "\n",
    "\n",
    "# Perform Object Detection with YOLO\n",
    "def detect_objects(image, net, output_layers, conf_threshold=0.5):\n",
    "    height, width = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(obj[0] * width)\n",
    "                center_y = int(obj[1] * height)\n",
    "                w = int(obj[2] * width)\n",
    "                h = int(obj[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Perform Non-Maximum Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, 0.4)\n",
    "    print(\"Indices:\", indices)\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        # Filter boxes using the flat indices array\n",
    "        filtered_boxes = [boxes[i] for i in indices.flatten()]\n",
    "    else:\n",
    "        filtered_boxes = []  # Return empty if no valid boxes\n",
    "\n",
    "    return filtered_boxes\n",
    "\n",
    "\n",
    "# Draw YOLO Bounding Boxes\n",
    "def draw_bounding_boxes(image, boxes, output_path):\n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"Object {i}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "\n",
    "# Crop Images to Smaller Size\n",
    "def crop_to_smaller(image1, image2):\n",
    "    h1, w1 = image1.shape[:2]\n",
    "    h2, w2 = image2.shape[:2]\n",
    "    target_height = min(h1, h2)\n",
    "    target_width = min(w1, w2)\n",
    "    return image1[:target_height, :target_width], image2[:target_height, :target_width]\n",
    "\n",
    "\n",
    "# Detect and Show Keypoints Using SIFT\n",
    "def detect_and_show_keypoints(image, detector):\n",
    "    # Check if image is empty\n",
    "    if image is None or image.size == 0:\n",
    "        print(\"Error: Empty image passed to keypoint detection.\")\n",
    "        return [], None\n",
    "    \n",
    "    # Convert image to grayscale if it's not already\n",
    "    if len(image.shape) == 3:  # Check if it's a color image (RGB)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    keypoints, descriptors = detector.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "# Match Keypoints with BFMatcher\n",
    "def match_keypoints_sift_with_bf(image1, image2, keypoints1, descriptors1, keypoints2, descriptors2, distance_threshold=50.0):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    good_matches = [m for m in matches if m.distance < 0.8 * np.mean([m.distance for m in matches])]\n",
    "\n",
    "    filtered_matches = []\n",
    "    for match in good_matches:\n",
    "        pt1 = keypoints1[match.queryIdx].pt\n",
    "        pt2 = keypoints2[match.trainIdx].pt\n",
    "        if np.linalg.norm(np.array(pt1) - np.array(pt2)) < distance_threshold:\n",
    "            filtered_matches.append(match)\n",
    "    \n",
    "    return filtered_matches\n",
    "\n",
    "\n",
    "# Process Stereo Images and Match Sub-Images with Duplicate Check\n",
    "def process_stereo_images(left_image_path, right_image_path, yolo_model, output_dir, target_class_name=\"pottedplant\"):\n",
    "    net, output_layers, classes = yolo_model\n",
    "\n",
    "    # Load images\n",
    "    left_image = cv2.imread(left_image_path)\n",
    "    right_image = cv2.imread(right_image_path)\n",
    "\n",
    "    if left_image is None or right_image is None:\n",
    "        print(\"Error loading images.\")\n",
    "        return\n",
    "\n",
    "    # Detect objects in both images\n",
    "    left_boxes = detect_objects(left_image, net, output_layers)\n",
    "    right_boxes = detect_objects(right_image, net, output_layers)\n",
    "\n",
    "    # Save YOLO bounding box visualizations\n",
    "    draw_bounding_boxes(left_image.copy(), left_boxes, os.path.join(output_dir, \"left_boxes.jpg\"))\n",
    "    draw_bounding_boxes(right_image.copy(), right_boxes, os.path.join(output_dir, \"right_boxes.jpg\"))\n",
    "\n",
    "    # Keep track of already matched boxes to avoid duplicates\n",
    "    matched_left_indices = set()\n",
    "    matched_right_indices = set()\n",
    "\n",
    "    # Process each detected object pair\n",
    "    sift = cv2.SIFT_create(nfeatures=12800)\n",
    "    for i, left_box in enumerate(left_boxes):\n",
    "        for j, right_box in enumerate(right_boxes):\n",
    "            \n",
    "            # Skip if either of the boxes has already been matched\n",
    "            if i in matched_left_indices or j in matched_right_indices:\n",
    "                continue\n",
    "\n",
    "            lx, ly, lw, lh = left_box\n",
    "            rx, ry, rw, rh = right_box\n",
    "\n",
    "            left_crop = left_image[ly:ly+lh, lx:lx+lw]\n",
    "            right_crop = right_image[ry:ry+rh, rx:rx+rw]\n",
    "\n",
    "            # Crop and normalize sizes\n",
    "            left_crop, right_crop = crop_to_smaller(left_crop, right_crop)\n",
    "\n",
    "            # Detect keypoints and descriptors\n",
    "            keypoints1, descriptors1 = detect_and_show_keypoints(left_crop, sift)\n",
    "            keypoints2, descriptors2 = detect_and_show_keypoints(right_crop, sift)\n",
    "\n",
    "            if not keypoints1 or not keypoints2:  # If keypoints are empty, skip matching\n",
    "                continue\n",
    "\n",
    "            # Match keypoints\n",
    "            filtered_matches = match_keypoints_sift_with_bf(left_crop, right_crop, keypoints1, descriptors1, keypoints2, descriptors2)\n",
    "\n",
    "            # If there are good matches, draw and save\n",
    "            if len(filtered_matches) > 8:\n",
    "                img_matches = cv2.drawMatches(left_crop, keypoints1, right_crop, keypoints2, filtered_matches, None, flags=2)\n",
    "                match_path = os.path.join(output_dir, f\"matches_{i}_{j}.jpg\")\n",
    "                print(f\"matches_{i}_{j}.jpg saved\")\n",
    "                cv2.imwrite(match_path, img_matches)\n",
    "\n",
    "                # Mark the indices as matched to prevent further matching\n",
    "                matched_left_indices.add(i)\n",
    "                matched_right_indices.add(j)\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    yolo_cfg = \"yolov4.cfg\"\n",
    "    yolo_weights = \"yolov4.weights\"\n",
    "    yolo_names = \"coco.names\"\n",
    "    output_dir = \"output\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    yolo_model = load_yolo_model(yolo_cfg, yolo_weights, yolo_names)\n",
    "\n",
    "    left_path = \"IMG_7998.jpg\"\n",
    "    right_path = \"IMG_7999.jpg\"\n",
    "    process_stereo_images(left_path, right_path, yolo_model, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Example input: Increase the number of points as needed\n",
    "img1u = [6.407395839691162, 23.99433135986328, 36.878849029541016, 39.815406799316406, 57.57866668701172, 80.62291717529297, 85.26073455810547, 88.87594604492188, 113.35128021240234, 115.13031005859375, 120.58953094482422, 123.75055694580078, 125.09960174560547, 152.86256408691406, 152.86256408691406, 152.93055725097656, 153.6582794189453, 156.66094970703125, 161.39122009277344, 167.87033081054688, 174.47418212890625, 182.8557586669922, 183.5654754638672, 184.22274780273438, 196.97976684570312, 198.85235595703125, 227.01231384277344, 231.24362182617188, 246.11671447753906]\n",
    "img1v = [462.1249084472656, 454.4391174316406, 432.43865966796875, 103.53443908691406, 373.8476257324219, 236.81967163085938, 239.8443145751953, 390.337890625, 235.67897033691406, 231.36708068847656, 238.24728393554688, 492.7323913574219, 103.16875457763672, 471.3157958984375, 471.3157958984375, 434.3181457519531, 466.6029357910156, 285.0070495605469, 450.04693603515625, 400.6963806152344, 419.75213623046875, 493.987548828125, 480.3666076660156, 422.72467041015625, 50.67970657348633, 408.5749816894531, 68.35357666015625, 73.46319580078125, 111.0586166381836]\n",
    "img2u = [3.691209077835083, 14.697043418884277, 24.386083602905273, 61.63813018798828, 37.69493865966797, 95.7635726928711, 101.94422912597656, 93.55023956298828, 137.67079162597656, 138.65699768066406, 145.7137908935547, 136.86985778808594, 91.52183532714844, 169.7540740966797, 169.7540740966797, 169.84263610839844, 171.1566925048828, 188.53741455078125, 172.08990478515625, 178.7653350830078, 187.25868225097656, 194.6011962890625, 195.2294464111328, 198.1847381591797, 197.99534606933594, 208.58331298828125, 224.09152221679688, 230.73944091796875, 219.5247802734375]\n",
    "img2v = [484.1200866699219, 477.37652587890625, 452.7850646972656, 103.78766632080078, 388.2860107421875, 242.76962280273438, 246.01145935058594, 396.0755310058594, 240.02403259277344, 234.33604431152344, 242.39105224609375, 503.11505126953125, 101.1902084350586, 476.84912109375, 476.84912109375, 439.535400390625, 472.33221435546875, 286.5150146484375, 454.1869812011719, 406.70880126953125, 422.5718688964844, 498.4800720214844, 484.67431640625, 424.1497802734375, 44.91103744506836, 408.0655822753906, 58.360595703125, 68.58309173583984, 104.48462677001953]\n",
    "\n",
    "n = len(img1u)\n",
    "assert len(img1v) == n and len(img2u) == n and len(img2v) == n, \"Mismatch in number of points.\"\n",
    "\n",
    "# Initialize matrix A with the correct size\n",
    "A = np.zeros((n, 9), dtype=np.float64)\n",
    "\n",
    "# Populate matrix A\n",
    "for i in range(n):\n",
    "    A[i][0] = img1u[i] * img2u[i]\n",
    "    A[i][1] = img1v[i] * img2u[i]\n",
    "    A[i][2] = img2u[i]\n",
    "    A[i][3] = img1u[i] * img2v[i]\n",
    "    A[i][4] = img1v[i] * img2v[i]\n",
    "    A[i][5] = img2v[i]\n",
    "    A[i][6] = img1u[i]\n",
    "    A[i][7] = img1v[i]\n",
    "    A[i][8] = 1\n",
    "\n",
    "# Display matrix A\n",
    "print(\"Matrix A:\")\n",
    "print(tabulate(A))\n",
    "\n",
    "# Perform SVD on matrix A\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "\n",
    "# Extract the fundamental matrix (f is the last row of VT)\n",
    "f = VT[-1]\n",
    "print(\"\\nf (last row of VT):\", f)\n",
    "\n",
    "# Reshape into a 3x3 fundamental matrix\n",
    "F = f.reshape(3, 3)\n",
    "print(\"\\nFundamental Matrix F:\")\n",
    "print(F)\n",
    "\n",
    "# Force F to have rank 2 by setting the smallest singular value to 0\n",
    "U, Sigma, VT = np.linalg.svd(F)\n",
    "Sigma[2] = 0\n",
    "F2 = np.dot(U, np.dot(np.diag(Sigma), VT))\n",
    "print(\"\\nRank-2 Forced Fundamental Matrix F2:\")\n",
    "print(F2)\n",
    "\n",
    "# Use calibration matrix K (as in the original code)\n",
    "K = np.array([\n",
    "    [9.25692841e+03, 0, 4.58239711e+02],\n",
    "    [0, 8.37883743e+04, 3.59148084e+02],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "KTK = np.matmul(K.T, K)\n",
    "print(\"\\nKT * K:\")\n",
    "print(KTK)\n",
    "\n",
    "# Compute the essential matrix\n",
    "E = np.matmul(KTK, F2)\n",
    "print(\"\\nEssential Matrix E:\")\n",
    "print(E)\n",
    "\n",
    "# Verify ranks\n",
    "F2Rank = np.linalg.matrix_rank(F2)\n",
    "ERank = np.linalg.matrix_rank(E)\n",
    "print(\"\\nRanks:\")\n",
    "print(\"Rank of F2:\", F2Rank)\n",
    "print(\"Rank of E:\", ERank)\n",
    "\n",
    "# Extract translation vector t from E\n",
    "U, Sigma, VT = np.linalg.svd(E)\n",
    "t = U[:, 2]\n",
    "print(\"\\nTranslation Vector t:\")\n",
    "print(t)\n",
    "\n",
    "# Construct skew-symmetric matrix for t\n",
    "tX = np.array([\n",
    "    [0, -t[2], t[1]],\n",
    "    [t[2], 0, -t[0]],\n",
    "    [-t[1], t[0], 0]\n",
    "])\n",
    "print(\"\\n[t]x (Skew-Symmetric Matrix):\")\n",
    "print(tX)\n",
    "\n",
    "# Compute rotation matrix\n",
    "U, Sigma, VTt = np.linalg.svd(tX)\n",
    "R = np.matmul(VTt, VT.T)\n",
    "print(\"\\nRotation Matrix R:\")\n",
    "print(R)\n",
    "\n",
    "# Verify R is a valid rotation matrix\n",
    "print(\"\\nDeterminant of R:\", np.linalg.det(R))\n",
    "print(\"R * R^T:\")\n",
    "print(np.matmul(R, R.T))\n",
    "\n",
    "Xlist = []\n",
    "Rnew = -R\n",
    "tnew = (t + np.array([1, .1, 0])).reshape(3, 1)\n",
    "print(R)\n",
    "print(t)\n",
    "Rt = np.hstack((Rnew, tnew))\n",
    "print(\"Extrinsic Matrix:\\n\",Rt)\n",
    "\n",
    "P = np.matmul(K, Rt)\n",
    "print(\"Paramter Matrix:\\n\",P)\n",
    "\n",
    "imagepoints = np.vstack((img2u, img2v, np.ones_like(img2u)))\n",
    "print(imagepoints)\n",
    "\n",
    "for i in range(imagepoints.shape[1]):\n",
    "    row1 = img2u[i] * P[2, :] - P[0, :]\n",
    "    row2 = img2v[i] * P[2, :] - P[1, :]\n",
    "    A = np.array([row1, row2])\n",
    "    U, Sigma, VT = np.linalg.svd(A)\n",
    "    X = VT[-1]\n",
    "    X = X / X[-1]\n",
    "\n",
    "    Xlist.append(X[:-1])\n",
    "\n",
    "print(Xlist)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "Xlist2 = [np.array(coord) for coord in Xlist]\n",
    "Xlist2array = np.array(Xlist2)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Xlist2array[:, 0], Xlist2array[:, 1], Xlist2array[:, 2], c='b', marker='o')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
